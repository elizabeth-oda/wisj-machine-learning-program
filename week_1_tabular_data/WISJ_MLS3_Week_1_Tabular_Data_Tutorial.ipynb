{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# WISJ Summer School: Tabular ML Workshop\n",
        "## Module 1: E-commerce Dataset Generation\n",
        "\n",
        "**Instructor**: Marco Visentini-Scarzanella, Sr. Manager Applied Science, Amazon Japan\n",
        "\n",
        "---\n",
        "\n",
        "### **E-commerce Product Success Prediction**\n",
        "\n",
        "In this workshop, we'll predict the **success score (0-100)** of products on an e-commerce platform. This is a regression problem where we analyze how various product and seller characteristics influence product performance.\n",
        "\n",
        "**Learning Objectives:**\n",
        "1. Understand how to explore datasets\n",
        "2. See the impact of feature correlations and data quality issues\n",
        "3. Prepare for the complete ML pipeline (preprocessing → modeling → evaluation)\n",
        "\n",
        "---\n",
        "\n",
        "###**Dataset Features Overview**\n",
        "\n",
        "**Numerical Features:**\n",
        "- `price`: Product price ($10-$500, log-normal distribution)\n",
        "- `seller_rating`: Seller rating (1-5, normal distribution)\n",
        "- `product_weight`: Product weight (0.1-20kg, log-normal)\n",
        "- `days_since_launch`: Days since product launch (1-365)\n",
        "- `description_length`: Description length (100-2000 characters)\n",
        "\n",
        "**Categorical Features:**\n",
        "- `category`: Electronics, Clothing, Home, Sports, Books\n",
        "- `shipping_method`: Standard, Express, Overnight\n",
        "- `seller_type`: Individual, Business, Premium\n",
        "\n",
        "**Ordinal/Binary Features:**\n",
        "- `product_condition`: 1-4 (Fair to New)\n",
        "- `seller_experience`: 1-3 (Beginner to Expert)\n",
        "- `has_reviews`: 0/1 (Boolean)\n",
        "- `international_shipping`: 0/1 (Boolean)\n",
        "\n",
        "**Target Variable:**\n",
        "- `success_score`: Product success score (0-100, continuous)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURATION (Adjustable for different class sizes)\n",
        "DATASET_SIZE = 500        # Options: 500, 1000, 2000 (adjust based on class needs)\n",
        "RANDOM_SEED = 123           # For reproducible results across all students\n",
        "INCLUDE_DATA_ISSUES = True # Add realistic missing values & outliers"
      ],
      "metadata": {
        "id": "KKdyKJ6YNF4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 1: Data generation\n",
        "## (Run once and then collapse)"
      ],
      "metadata": {
        "id": "78fLuTJ8Werz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "module1_complete",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# ===================================================================\n",
        "# WISJ Summer School: Tabular ML Workshop - Module 1\n",
        "# E-commerce Dataset Generation\n",
        "# ===================================================================\n",
        "\n",
        "# IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from scipy import stats\n",
        "import warnings\n",
        "import time\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Optional libraries\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "    print(\"XGBoost available\")\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    print(\"Using RandomForest instead of XGBoost\")\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "    print(\"SHAP available\")\n",
        "except ImportError:\n",
        "    SHAP_AVAILABLE = False\n",
        "    print(\"SHAP not available\")\n",
        "\n",
        "\n",
        "# Set plotting style for inline display\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Libraries imported successfully! Ready to generate data.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"Dataset Size: {DATASET_SIZE:,} samples\")\n",
        "print(f\"Random Seed: {RANDOM_SEED} (for reproducibility)\")\n",
        "print(f\"Data Issues: {'Included' if INCLUDE_DATA_ISSUES else 'Clean dataset'}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# HELPER FUNCTIONS\n",
        "\n",
        "def generate_correlated_numerical_features(n_samples, random_state):\n",
        "    \"\"\"Generate 5 correlated numerical features using multivariate normal distribution.\"\"\"\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Define realistic correlation matrix based on e-commerce domain knowledge\n",
        "    corr_matrix = np.array([\n",
        "        #       price  rating  weight  days  desc_len\n",
        "        [1.00, -0.15,   0.25,  0.10,   0.20],  # price: neg with rating, pos with weight/desc\n",
        "        [-0.15, 1.00,  -0.05,  0.40,   0.30],  # rating: pos with time/desc (experienced sellers)\n",
        "        [0.25, -0.05,   1.00,  0.05,   0.15],  # weight: pos with price/desc\n",
        "        [0.10,  0.40,   0.05,  1.00,   0.35],  # days: pos with rating/desc (established products)\n",
        "        [0.20,  0.30,   0.15,  0.35,   1.00]   # desc_len: pos with all (effort correlates)\n",
        "    ])\n",
        "\n",
        "    # Generate multivariate normal samples\n",
        "    mvn_samples = np.random.multivariate_normal(\n",
        "        mean=np.zeros(5), cov=corr_matrix, size=n_samples\n",
        "    )\n",
        "\n",
        "    # Transform to desired distributions\n",
        "    price = np.exp(mvn_samples[:, 0] * 0.6 + 3.8)\n",
        "    seller_rating = np.clip(mvn_samples[:, 1] * 0.7 + 4.0, 1.0, 5.0)\n",
        "    product_weight = np.exp(mvn_samples[:, 2] * 0.8 + 0.5)\n",
        "    days_since_launch = np.clip((mvn_samples[:, 3] + 2) * 60, 1, 365).astype(int)\n",
        "    description_length = np.clip(mvn_samples[:, 4] * 200 + 800, 100, 2000).astype(int)\n",
        "\n",
        "    return price, seller_rating, product_weight, days_since_launch, description_length\n",
        "\n",
        "\n",
        "def generate_target_simple(df):\n",
        "    \"\"\"Generate target variable (success_score) using realistic business relationships.\"\"\"\n",
        "    # Normalize numerical features to [0,1] for consistent weighting\n",
        "    norm_rating = (df['seller_rating'] - 1) / 4  # 1-5 → 0-1\n",
        "    norm_time = np.log(df['days_since_launch'] + 1) / np.log(366)  # Log normalize time\n",
        "    norm_price_inv = 1 / (1 + df['price'] / 100)  # Inverse relationship, bounded\n",
        "\n",
        "    # Category effects (some categories naturally perform better)\n",
        "    category_effects = {\n",
        "        'Electronics': 15, 'Clothing': 10, 'Home': 12, 'Sports': 8, 'Books': 5\n",
        "    }\n",
        "    category_score = df['category'].map(category_effects)\n",
        "\n",
        "    # Other feature effects\n",
        "    condition_score = df['product_condition'] * 2.5  # 1→2.5, 4→10\n",
        "    reviews_score = df['has_reviews'] * 10  # Reviews provide social proof\n",
        "\n",
        "    shipping_effects = {'Standard': 0, 'Express': 3, 'Overnight': 5}\n",
        "    shipping_score = df['shipping_method'].map(shipping_effects)\n",
        "\n",
        "    seller_type_effects = {'Individual': 0, 'Business': 5, 'Premium': 10}\n",
        "    seller_type_score = df['seller_type'].map(seller_type_effects)\n",
        "\n",
        "    # Linear combination of all effects (business-driven weights)\n",
        "    base_score = (\n",
        "        30 * norm_rating +           # Main predictor (30 points max)\n",
        "        20 * norm_time +             # Time matters, logarithmic (20 points max)\n",
        "        category_score +             # Category bias (5-15 points)\n",
        "        condition_score +            # Condition effect (2.5-10 points)\n",
        "        reviews_score +              # Reviews effect (0 or 10 points)\n",
        "        10 * norm_price_inv +        # Price effect, inverse (up to 10 points)\n",
        "        shipping_score +             # Shipping effect (0-5 points)\n",
        "        seller_type_score            # Seller type effect (0-10 points)\n",
        "    )\n",
        "\n",
        "    # Add controlled noise (±8 points standard deviation)\n",
        "    np.random.seed(42)  # Fixed seed for reproducible noise\n",
        "    noise = np.random.normal(0, 8, len(df))\n",
        "\n",
        "    # Final score, clipped to [0, 100]\n",
        "    success_score = np.clip(base_score + noise, 0, 100)\n",
        "\n",
        "    return success_score\n",
        "\n",
        "\n",
        "def inject_data_problems(df):\n",
        "    \"\"\"Add realistic data quality issues to simulate real-world challenges.\"\"\"\n",
        "    df_dirty = df.copy()\n",
        "    n_samples = len(df_dirty)\n",
        "\n",
        "    # Set seed for reproducible problems\n",
        "    np.random.seed(123)\n",
        "\n",
        "    # MISSING VALUES WITH REALISTIC PATTERNS\n",
        "\n",
        "    # 1. New/inexperienced sellers often missing ratings\n",
        "    mask_new_sellers = df_dirty['seller_experience'] == 1\n",
        "    missing_rating_prob = np.where(mask_new_sellers, 0.3, 0.05)\n",
        "    missing_rating_mask = np.random.random(n_samples) < missing_rating_prob\n",
        "    df_dirty.loc[missing_rating_mask, 'seller_rating'] = np.nan\n",
        "\n",
        "    # 2. Books and digital products often missing weight\n",
        "    mask_books = df_dirty['category'] == 'Books'\n",
        "    missing_weight_prob = np.where(mask_books, 0.4, 0.08)\n",
        "    missing_weight_mask = np.random.random(n_samples) < missing_weight_prob\n",
        "    df_dirty.loc[missing_weight_mask, 'product_weight'] = np.nan\n",
        "\n",
        "    # 3. Random missing description lengths (lazy sellers)\n",
        "    missing_desc_mask = np.random.random(n_samples) < 0.1\n",
        "    df_dirty.loc[missing_desc_mask, 'description_length'] = np.nan\n",
        "\n",
        "    # 4. Some missing launch dates (data collection issues)\n",
        "    missing_days_mask = np.random.random(n_samples) < 0.05\n",
        "    df_dirty.loc[missing_days_mask, 'days_since_launch'] = np.nan\n",
        "\n",
        "    # OUTLIERS (affect ~5% of data)\n",
        "    n_outliers = int(0.05 * n_samples)\n",
        "    outlier_indices = np.random.choice(n_samples, n_outliers, replace=False)\n",
        "\n",
        "    # Price outliers: luxury/premium items with extreme prices\n",
        "    price_outlier_indices = outlier_indices[:n_outliers//2]\n",
        "    df_dirty.loc[price_outlier_indices, 'price'] *= np.random.uniform(5, 15, len(price_outlier_indices))\n",
        "\n",
        "    # Rating outliers: fake perfect ratings\n",
        "    rating_outlier_indices = outlier_indices[n_outliers//2:]\n",
        "    df_dirty.loc[rating_outlier_indices, 'seller_rating'] = 5.0\n",
        "\n",
        "    # Weight outliers: extremely light items (digital products coded wrong)\n",
        "    weight_outlier_count = max(1, n_outliers//4)\n",
        "    weight_outlier_indices = np.random.choice(outlier_indices, weight_outlier_count, replace=False)\n",
        "    df_dirty.loc[weight_outlier_indices, 'product_weight'] = np.random.uniform(0.001, 0.01, weight_outlier_count)\n",
        "\n",
        "    return df_dirty\n",
        "\n",
        "\n",
        "def generate_ecommerce_dataset(n_samples=1000, random_state=42, include_issues=True):\n",
        "    \"\"\"MAIN FUNCTION: Generate the complete e-commerce dataset.\"\"\"\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Generate correlated numerical features\n",
        "    price, seller_rating, product_weight, days_since_launch, description_length = \\\n",
        "        generate_correlated_numerical_features(n_samples, random_state)\n",
        "\n",
        "    # Generate independent categorical features\n",
        "    categories = ['Electronics', 'Clothing', 'Home', 'Sports', 'Books']\n",
        "    category = np.random.choice(categories, n_samples, p=[0.3, 0.25, 0.2, 0.15, 0.1])\n",
        "\n",
        "    shipping_methods = ['Standard', 'Express', 'Overnight']\n",
        "    shipping_method = np.random.choice(shipping_methods, n_samples, p=[0.6, 0.3, 0.1])\n",
        "\n",
        "    seller_types = ['Individual', 'Business', 'Premium']\n",
        "    seller_type = np.random.choice(seller_types, n_samples, p=[0.4, 0.5, 0.1])\n",
        "\n",
        "    # Generate independent ordinal and binary features\n",
        "    product_condition = np.random.choice([1, 2, 3, 4], n_samples, p=[0.1, 0.2, 0.3, 0.4])\n",
        "    seller_experience = np.random.choice([1, 2, 3], n_samples, p=[0.3, 0.5, 0.2])\n",
        "    has_reviews = np.random.choice([0, 1], n_samples, p=[0.3, 0.7])\n",
        "    international_shipping = np.random.choice([0, 1], n_samples, p=[0.6, 0.4])\n",
        "\n",
        "    # Generate noise features (irrelevant for prediction - educational purpose)\n",
        "    listing_id = [f\"ITEM_{i:06d}\" for i in range(n_samples)]\n",
        "    seller_location_code = np.random.randint(10000, 99999, n_samples)\n",
        "\n",
        "    # Create clean DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'listing_id': listing_id,\n",
        "        'price': price,\n",
        "        'seller_rating': seller_rating,\n",
        "        'product_weight': product_weight,\n",
        "        'days_since_launch': days_since_launch,\n",
        "        'description_length': description_length,\n",
        "        'category': category,\n",
        "        'shipping_method': shipping_method,\n",
        "        'seller_type': seller_type,\n",
        "        'product_condition': product_condition,\n",
        "        'seller_experience': seller_experience,\n",
        "        'has_reviews': has_reviews,\n",
        "        'international_shipping': international_shipping,\n",
        "        'seller_location_code': seller_location_code\n",
        "    })\n",
        "\n",
        "    # Generate target variable\n",
        "    df['success_score'] = generate_target_simple(df)\n",
        "\n",
        "    # Add data quality issues if requested\n",
        "    if include_issues:\n",
        "        df = inject_data_problems(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def print_dataset_summary(df):\n",
        "    \"\"\"Print a comprehensive summary of the generated dataset.\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"E-COMMERCE DATASET SUMMARY\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(f\"\\nDataset Structure:\")\n",
        "    print(f\"   Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
        "    print(f\"   Memory usage: ~{df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
        "\n",
        "    print(f\"\\nTarget Variable (success_score):\")\n",
        "    print(f\"   Mean: {df['success_score'].mean():.2f}\")\n",
        "    print(f\"   Std:  {df['success_score'].std():.2f}\")\n",
        "    print(f\"   Range: {df['success_score'].min():.1f} - {df['success_score'].max():.1f}\")\n",
        "\n",
        "    print(f\"\\nMissing Values Analysis:\")\n",
        "    missing_counts = df.isnull().sum()\n",
        "    missing_features = missing_counts[missing_counts > 0]\n",
        "    if len(missing_features) > 0:\n",
        "        print(f\"   Total missing values: {missing_counts.sum():,}\")\n",
        "        for feature, count in missing_features.items():\n",
        "            pct = (count / len(df)) * 100\n",
        "            print(f\"   {feature}: {count:,} ({pct:.1f}%)\")\n",
        "    else:\n",
        "        print(\"No missing values detected\")\n",
        "\n",
        "    print(f\"\\nFeature Types Breakdown:\")\n",
        "    numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "    # Remove target from numerical count\n",
        "    if 'success_score' in numerical_features:\n",
        "        numerical_features.remove('success_score')\n",
        "    print(f\"Numerical: {len(numerical_features)} features\")\n",
        "    print(f\"Categorical: {len(categorical_features)} features\")\n",
        "    print(f\"Target: 1 feature (success_score)\")\n",
        "\n",
        "    print(f\"\\nFeature Correlations (Top 5 Numerical):\")\n",
        "    numerical_cols = ['price', 'seller_rating', 'product_weight', 'days_since_launch', 'description_length']\n",
        "    corr_matrix = df[numerical_cols].corr()\n",
        "    print(\"   Correlation Matrix:\")\n",
        "    print(corr_matrix.round(3).to_string())\n",
        "\n",
        "    print(f\"\\nCategory Distribution:\")\n",
        "    category_dist = df['category'].value_counts()\n",
        "    for cat, count in category_dist.items():\n",
        "        pct = (count / len(df)) * 100\n",
        "        print(f\"   {cat}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# DATASET GENERATION & ANALYSIS\n",
        "# ===================================================================\n",
        "\n",
        "print(\"\\nGenerating E-commerce Dataset...\")\n",
        "print(f\"Creating {DATASET_SIZE:,} product records with realistic relationships...\")\n",
        "\n",
        "# Generate the dataset\n",
        "dataset = generate_ecommerce_dataset(\n",
        "    n_samples=DATASET_SIZE,\n",
        "    random_state=RANDOM_SEED,\n",
        "    include_issues=INCLUDE_DATA_ISSUES\n",
        ")\n",
        "\n",
        "print(f\"Dataset generation complete!\")\n",
        "print(f\"Generated {dataset.shape[0]:,} products with {dataset.shape[1]} features\")\n",
        "\n",
        "# Print comprehensive analysis\n",
        "print_dataset_summary(dataset)\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\nSample Data (First 5 rows):\")\n",
        "print(\"=\" * 70)\n",
        "display(dataset.head())\n",
        "\n",
        "# Final status\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MODULE 1 COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Dataset ready: {dataset.shape[0]:,} products × {dataset.shape[1]} features\")\n",
        "print(f\"Variable name: 'dataset' (use this in Module 2)\")\n",
        "print(f\"Target variable: 'success_score' (continuous values 0-100)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module 2: Data Preprocessing & Visualization\n",
        "### Cell 1: Setup & Helper Functions\n",
        "### Instructions\n",
        "\n",
        "**Run this cell once, then collapse it to keep your notebook clean.**\n",
        "\n",
        "This cell contains:\n",
        "- All necessary imports\n",
        "- Helper functions for visualizations\n",
        "- EDA dashboard function\n",
        "- Configuration for inline plotting\n",
        "\n",
        "**Prerequisites**: This module expects the `dataset` variable from Module 1 to be available."
      ],
      "metadata": {
        "id": "hbopltxAVNdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup & Helper Functions (Run Once, Then Collapse)\n",
        "\n",
        "# ==========================================\n",
        "# COMPREHENSIVE EDA DASHBOARD FUNCTION\n",
        "# ==========================================\n",
        "\n",
        "def create_eda_dashboard(df):\n",
        "    \"\"\"Create comprehensive EDA dashboard with 9 panels.\"\"\"\n",
        "    fig = plt.figure(figsize=(18, 12))\n",
        "\n",
        "    # 1. Missing values heatmap\n",
        "    plt.subplot(3, 3, 1)\n",
        "    sns.heatmap(df.isnull(), yticklabels=False, cbar=True, cmap='RdYlBu_r')\n",
        "    plt.title('Missing Values Heatmap', fontweight='bold')\n",
        "\n",
        "    # 2. Missing values by feature\n",
        "    plt.subplot(3, 3, 2)\n",
        "    missing_counts = df.isnull().sum()\n",
        "    missing_features = missing_counts[missing_counts > 0]\n",
        "    if len(missing_features) > 0:\n",
        "        missing_pct = (missing_features / len(df)) * 100\n",
        "        bars = plt.bar(range(len(missing_features)), missing_pct.values, color='coral')\n",
        "        plt.xticks(range(len(missing_features)),\n",
        "                  [col.replace('_', '\\n') for col in missing_features.index],\n",
        "                  rotation=0, fontsize=9)\n",
        "        plt.ylabel('Missing %')\n",
        "        plt.title('Missing Values by Feature', fontweight='bold')\n",
        "        # Add percentage labels on bars\n",
        "        for i, bar in enumerate(bars):\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.2,\n",
        "                    f'{height:.1f}%', ha='center', va='bottom', fontsize=8)\n",
        "    else:\n",
        "        plt.text(0.5, 0.5, 'No Missing Values', ha='center', va='center',\n",
        "                transform=plt.gca().transAxes, fontsize=12)\n",
        "        plt.title('Missing Values by Feature', fontweight='bold')\n",
        "\n",
        "    # 3. Feature correlations\n",
        "    plt.subplot(3, 3, 3)\n",
        "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if 'success_score' in numerical_cols:\n",
        "        numerical_cols.remove('success_score')\n",
        "    if len(numerical_cols) > 1:\n",
        "        corr_matrix = df[numerical_cols].corr()\n",
        "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "                    square=True, linewidths=0.5, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
        "    plt.title('Feature Correlations', fontweight='bold')\n",
        "\n",
        "    # 4. Target distribution\n",
        "    plt.subplot(3, 3, 4)\n",
        "    if 'success_score' in df.columns:\n",
        "        plt.hist(df['success_score'].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        plt.axvline(df['success_score'].mean(), color='red', linestyle='--',\n",
        "                    label=f'Mean: {df[\"success_score\"].mean():.1f}')\n",
        "        plt.xlabel('Success Score')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.title('Target Distribution', fontweight='bold')\n",
        "        plt.legend()\n",
        "\n",
        "    # 5. Price distribution\n",
        "    plt.subplot(3, 3, 5)\n",
        "    if 'price' in df.columns:\n",
        "        plt.hist(df['price'].dropna(), bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "        plt.axvline(df['price'].mean(), color='red', linestyle='--', alpha=0.7)\n",
        "        plt.title('Price Distribution', fontweight='bold')\n",
        "        plt.xlabel('Price ($)')\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "    # 6. Category analysis\n",
        "    plt.subplot(3, 3, 6)\n",
        "    if 'category' in df.columns:\n",
        "        df['category'].value_counts().plot(kind='bar', color='orange', alpha=0.7)\n",
        "        plt.title('Category Distribution', fontweight='bold')\n",
        "        plt.xlabel('Category')\n",
        "        plt.ylabel('Count')\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "    # 7. Seller rating vs success scatter\n",
        "    plt.subplot(3, 3, 7)\n",
        "    if 'seller_rating' in df.columns and 'success_score' in df.columns:\n",
        "        clean_data = df[['seller_rating', 'success_score']].dropna()\n",
        "        plt.scatter(clean_data['seller_rating'], clean_data['success_score'],\n",
        "                   alpha=0.6, s=20, color='purple')\n",
        "        plt.xlabel('Seller Rating')\n",
        "        plt.ylabel('Success Score')\n",
        "        plt.title('Rating vs Success', fontweight='bold')\n",
        "        # Add trend line if we have enough data\n",
        "        if len(clean_data) > 1:\n",
        "            z = np.polyfit(clean_data['seller_rating'], clean_data['success_score'], 1)\n",
        "            p = np.poly1d(z)\n",
        "            plt.plot(clean_data['seller_rating'], p(clean_data['seller_rating']),\n",
        "                    \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "    # 8. Price outliers boxplot\n",
        "    plt.subplot(3, 3, 8)\n",
        "    if 'price' in df.columns:\n",
        "        plt.boxplot(df['price'].dropna())\n",
        "        plt.title('Price Distribution\\n(Outliers Visible)', fontweight='bold')\n",
        "        plt.ylabel('Price ($)')\n",
        "\n",
        "    # 9. Dataset summary\n",
        "    plt.subplot(3, 3, 9)\n",
        "    plt.axis('off')\n",
        "    summary_text = f\"\"\"DATASET SUMMARY\n",
        "\n",
        "Shape: {df.shape[0]} rows × {df.shape[1]} columns\n",
        "\n",
        "Feature Types:\n",
        "- Numerical: {len(df.select_dtypes(include=[np.number]).columns)}\n",
        "- Categorical: {len(df.select_dtypes(include=['object']).columns)}\n",
        "\n",
        "Missing Values: {df.isnull().sum().sum()} total\n",
        "\n",
        "Target Variable (success_score):\n",
        "- Mean: {df['success_score'].mean():.1f}\n",
        "- Std: {df['success_score'].std():.1f}\n",
        "- Range: {df['success_score'].min():.1f} - {df['success_score'].max():.1f}\n",
        "\n",
        "Key Features:\n",
        "- Price range: ${df['price'].min():.0f} - ${df['price'].max():.0f}\n",
        "- Categories: {df['category'].nunique() if 'category' in df.columns else 'N/A'}\n",
        "- Sellers: {df['seller_rating'].count() if 'seller_rating' in df.columns else 'N/A'} rated\"\"\"\n",
        "\n",
        "    plt.text(0.05, 0.95, summary_text, transform=plt.gca().transAxes, fontsize=9,\n",
        "             verticalalignment='top',\n",
        "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgray', alpha=0.8))\n",
        "    plt.title('Dataset Summary', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# VISUALIZATION HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "\n",
        "def create_comparison_bar_chart(data_dict, title, ylabel, ax=None):\n",
        "    \"\"\"Create a bar chart comparing different categories with value labels.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    categories = list(data_dict.keys())\n",
        "    values = list(data_dict.values())\n",
        "    colors = ['coral', 'lightgreen', 'skyblue', 'orange', 'lightpink'][:len(categories)]\n",
        "\n",
        "    bars = ax.bar(categories, values, color=colors)\n",
        "    ax.set_title(title, fontweight='bold')\n",
        "    ax.set_ylabel(ylabel)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + max(values)*0.01,\n",
        "                f'{height:.1f}' if isinstance(height, float) else f'{int(height)}',\n",
        "                ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    return ax\n",
        "\n",
        "def create_distribution_comparison(data_before, data_after, feature_name, method_name, ax=None):\n",
        "    \"\"\"Create overlapping histograms to compare distributions before and after processing.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    ax.hist(data_before.dropna(), bins=30, alpha=0.7, label='Before',\n",
        "            color='coral', edgecolor='black', density=True)\n",
        "    ax.hist(data_after.dropna(), bins=30, alpha=0.7, label=f'After {method_name}',\n",
        "            color='lightgreen', edgecolor='black', density=True)\n",
        "\n",
        "    ax.set_title(f'Distribution Comparison: {feature_name}', fontweight='bold')\n",
        "    ax.set_xlabel(feature_name.replace('_', ' ').title())\n",
        "    ax.set_ylabel('Density')\n",
        "    ax.legend()\n",
        "\n",
        "    return ax\n",
        "\n",
        "print(\"Preprocessing functions loaded.\")\n",
        "\n",
        "\n",
        "def create_performance_comparison_chart(results_dict, metric='r2', title=\"Model Performance\", ax=None):\n",
        "    \"\"\"Create bar chart comparing model performance.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    models = list(results_dict.keys())\n",
        "    scores = [results_dict[model]['metrics'][metric] for model in models]\n",
        "    colors = ['coral', 'lightgreen', 'skyblue', 'orange', 'lightpink'][:len(models)]\n",
        "\n",
        "    bars = ax.bar(models, scores, color=colors)\n",
        "    ax.set_title(title, fontweight='bold')\n",
        "    ax.set_ylabel(f'{metric.upper()} Score')\n",
        "\n",
        "    # Add value labels\n",
        "    for bar, score in zip(bars, scores):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + max(scores)*0.01,\n",
        "                f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    return ax\n",
        "\n",
        "\n",
        "def create_prediction_scatter(y_true, y_pred, model_name, ax=None):\n",
        "    \"\"\"Create actual vs predicted scatter plot.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    ax.scatter(y_true, y_pred, alpha=0.6, s=20, color='skyblue')\n",
        "\n",
        "    # Perfect prediction line\n",
        "    min_val = min(min(y_true), min(y_pred))\n",
        "    max_val = max(max(y_true), max(y_pred))\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, label='Perfect Prediction')\n",
        "\n",
        "    ax.set_xlabel('Actual Values')\n",
        "    ax.set_ylabel('Predicted Values')\n",
        "    ax.set_title(f'Predictions: {model_name}', fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add R² score\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    ax.text(0.05, 0.95, f'R² = {r2:.3f}', transform=ax.transAxes,\n",
        "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def create_residual_plots(y_true, y_pred, model_name, ax=None):\n",
        "    \"\"\"Create residual plot for regression analysis.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    residuals = y_true - y_pred\n",
        "    ax.scatter(y_pred, residuals, alpha=0.6, s=20, color='coral')\n",
        "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
        "    ax.set_xlabel('Predicted Values')\n",
        "    ax.set_ylabel('Residuals')\n",
        "    ax.set_title(f'Residual Plot: {model_name}', fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def create_feature_importance_plot(importance_values, feature_names, model_name, ax=None, top_k=10):\n",
        "    \"\"\"Create horizontal bar plot for feature importance.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Sort and take top k\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': importance_values\n",
        "    }).sort_values('importance', ascending=True).tail(top_k)\n",
        "\n",
        "    bars = ax.barh(range(len(importance_df)), importance_df['importance'], color='skyblue')\n",
        "    ax.set_yticks(range(len(importance_df)))\n",
        "    ax.set_yticklabels([f.replace('_', ' ') for f in importance_df['feature']])\n",
        "    ax.set_xlabel('Importance')\n",
        "    ax.set_title(f'Top {top_k} Features: {model_name}', fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def create_cv_scores_boxplot(cv_results, model_names, ax=None):\n",
        "    \"\"\"Create boxplot for cross-validation scores.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    scores_list = [cv_results[model] for model in model_names]\n",
        "    bp = ax.boxplot(scores_list, labels=model_names, patch_artist=True)\n",
        "\n",
        "    colors = ['coral', 'lightgreen', 'skyblue', 'orange', 'lightpink'][:len(model_names)]\n",
        "    for patch, color in zip(bp['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    ax.set_title('Cross-Validation Scores', fontweight='bold')\n",
        "    ax.set_ylabel('R² Score')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def create_model_summary_text(results_dict, title, ax=None):\n",
        "    \"\"\"Create text summary of model results.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    ax.axis('off')\n",
        "    summary_text = f\"{title}\\n\\n\"\n",
        "\n",
        "    for model_name, results in results_dict.items():\n",
        "        metrics = results['metrics']\n",
        "        summary_text += f\"{model_name}:\\n\"\n",
        "        summary_text += f\"  • R² Score: {metrics['r2']:.3f}\\n\"\n",
        "        summary_text += f\"  • RMSE: {np.sqrt(metrics['mse']):.3f}\\n\"\n",
        "        summary_text += f\"  • MAE: {metrics['mae']:.3f}\\n\\n\"\n",
        "\n",
        "    if results_dict:\n",
        "        best_model = max(results_dict.keys(), key=lambda x: results_dict[x]['metrics']['r2'])\n",
        "        summary_text += f\"Best: {best_model}\"\n",
        "\n",
        "    ax.text(0.05, 0.95, summary_text, transform=ax.transAxes, fontsize=11,\n",
        "            verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "    ax.set_title(title, fontweight='bold')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def save_and_show_plot(filename=None):\n",
        "    \"\"\"Standardized plot saving and showing.\"\"\"\n",
        "    plt.tight_layout()\n",
        "    if filename:\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Saved: {filename}\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"Helper functions loaded.\")\n",
        "\n",
        "\n",
        "def create_linear_regression_dashboard(results, X_test, y_test, save_name='linear_analysis.png'):\n",
        "    \"\"\"Create 6-panel linear regression dashboard.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('Linear Regression Analysis Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Performance comparison\n",
        "    model_comparison = {name: {'metrics': res['metrics']} for name, res in results.items()}\n",
        "    create_performance_comparison_chart(model_comparison, 'r2', 'Model Comparison', axes[0, 0])\n",
        "\n",
        "    # 2. Best model predictions\n",
        "    best_model_name = max(results.keys(), key=lambda x: results[x]['metrics']['r2'])\n",
        "    best_model = results[best_model_name]['model']\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    create_prediction_scatter(y_test, y_pred, f'Best: {best_model_name}', axes[0, 1])\n",
        "\n",
        "    # 3. Residuals\n",
        "    create_residual_plots(y_test, y_pred, f'Best: {best_model_name}', axes[0, 2])\n",
        "\n",
        "    # 4. Feature importance\n",
        "    if hasattr(best_model, 'coef_'):\n",
        "        coef_values = np.abs(best_model.coef_)\n",
        "        feature_names = getattr(X_test, 'columns', [f'Feature_{i}' for i in range(len(coef_values))])\n",
        "        create_feature_importance_plot(coef_values, feature_names, best_model_name, axes[1, 0])\n",
        "\n",
        "    # 5. Cross-validation\n",
        "    cv_scores = {name: res['cv_scores'] for name, res in results.items()}\n",
        "    create_cv_scores_boxplot(cv_scores, list(cv_scores.keys()), axes[1, 1])\n",
        "\n",
        "    # 6. Summary\n",
        "    create_model_summary_text(results, 'Linear Models Summary', axes[1, 2])\n",
        "\n",
        "    save_and_show_plot(save_name)\n",
        "\n",
        "\n",
        "def create_xgboost_analysis_dashboard(results, X_test, y_test, feature_names=None, save_name='xgboost_analysis.png'):\n",
        "    \"\"\"Create 6-panel XGBoost dashboard.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('XGBoost Analysis Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "    model = results['model']\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 1. Predictions\n",
        "    create_prediction_scatter(y_test, y_pred, 'XGBoost', axes[0, 0])\n",
        "\n",
        "    # 2. Residuals\n",
        "    create_residual_plots(y_test, y_pred, 'XGBoost', axes[0, 1])\n",
        "\n",
        "    # 3. Feature importance\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        if feature_names is None:\n",
        "            feature_names = getattr(X_test, 'columns', [f'Feature_{i}' for i in range(X_test.shape[1])])\n",
        "        create_feature_importance_plot(model.feature_importances_, feature_names, 'XGBoost', axes[0, 2])\n",
        "\n",
        "\n",
        "    # 5. Hyperparameters\n",
        "    if 'best_params' in results:\n",
        "        axes[1, 1].axis('off')\n",
        "        param_text = \"🔧 Best Parameters:\\n\\n\"\n",
        "        for param, value in results['best_params'].items():\n",
        "            param_text += f\"• {param}: {value}\\n\"\n",
        "        axes[1, 1].text(0.1, 0.9, param_text, transform=axes[1, 1].transAxes,\n",
        "                       verticalalignment='top',\n",
        "                       bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
        "        axes[1, 1].set_title('Hyperparameters', fontweight='bold')\n",
        "\n",
        "    # 6. Summary\n",
        "    model_results = {'XGBoost': results}\n",
        "    create_model_summary_text(model_results, 'XGBoost Summary', axes[1, 2])\n",
        "\n",
        "    save_and_show_plot(save_name)\n",
        "\n",
        "\n",
        "def create_neural_network_dashboard(results, X_test, y_test, save_name='neural_network_analysis.png'):\n",
        "    \"\"\"Create 6-panel Neural Network dashboard.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('Neural Network Analysis Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "    model = results['model']\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 1. Predictions\n",
        "    create_prediction_scatter(y_test, y_pred, 'Neural Network', axes[0, 0])\n",
        "\n",
        "    # 2. Residuals\n",
        "    create_residual_plots(y_test, y_pred, 'Neural Network', axes[0, 1])\n",
        "\n",
        "    # 3. Training history\n",
        "    if 'training_history' in results and results['training_history'] is not None:\n",
        "        axes[0, 2].plot(results['training_history'], color='coral')\n",
        "        axes[0, 2].set_title('Training Loss Curve', fontweight='bold')\n",
        "        axes[0, 2].set_xlabel('Iteration')\n",
        "        axes[0, 2].set_ylabel('Loss')\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "    else:\n",
        "        axes[0, 2].text(0.5, 0.5, 'Training history\\nnot available',\n",
        "                       ha='center', va='center', transform=axes[0, 2].transAxes)\n",
        "        axes[0, 2].set_title('Training Loss', fontweight='bold')\n",
        "\n",
        "    # 4. Architecture\n",
        "    axes[1, 0].axis('off')\n",
        "    if hasattr(model, 'hidden_layer_sizes'):\n",
        "        arch_text = f\"Architecture:\\n\\n\"\n",
        "        arch_text += f\"Input: {X_test.shape[1]} neurons\\n\"\n",
        "        for i, size in enumerate(model.hidden_layer_sizes):\n",
        "            arch_text += f\"Hidden {i+1}: {size} neurons\\n\"\n",
        "        arch_text += f\"Output: 1 neuron\\n\\n\"\n",
        "        arch_text += f\"Activation: {getattr(model, 'activation', 'relu')}\"\n",
        "\n",
        "        axes[1, 0].text(0.1, 0.9, arch_text, transform=axes[1, 0].transAxes,\n",
        "                       verticalalignment='top',\n",
        "                       bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.8))\n",
        "    axes[1, 0].set_title('Network Architecture', fontweight='bold')\n",
        "\n",
        "    # 5. Hyperparameters\n",
        "    if 'best_params' in results:\n",
        "        axes[1, 1].axis('off')\n",
        "        param_text = \"🔧 Best Parameters:\\n\\n\"\n",
        "        for param, value in results['best_params'].items():\n",
        "            param_text += f\"• {param}: {value}\\n\"\n",
        "        axes[1, 1].text(0.1, 0.9, param_text, transform=axes[1, 1].transAxes,\n",
        "                       verticalalignment='top',\n",
        "                       bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
        "        axes[1, 1].set_title('Hyperparameters', fontweight='bold')\n",
        "\n",
        "    # 6. Summary\n",
        "    model_results = {'Neural Network': results}\n",
        "    create_model_summary_text(model_results, 'Neural Network Summary', axes[1, 2])\n",
        "\n",
        "    save_and_show_plot(save_name)\n",
        "\n",
        "\n",
        "def create_model_comparison_dashboard(all_results, save_name='model_comparison.png'):\n",
        "    \"\"\"Create comprehensive model comparison dashboard.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Model Comparison Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. R² comparison\n",
        "    create_performance_comparison_chart(all_results, 'r2', 'R² Score Comparison', axes[0, 0])\n",
        "\n",
        "    # 2. RMSE comparison\n",
        "    rmse_results = {}\n",
        "    for model, results in all_results.items():\n",
        "        rmse_results[model] = {'metrics': {'rmse': np.sqrt(results['metrics']['mse'])}}\n",
        "    create_performance_comparison_chart(rmse_results, 'rmse', 'RMSE Comparison', axes[0, 1])\n",
        "\n",
        "    # 3. Cross-validation comparison\n",
        "    cv_scores = {model: results['cv_scores'] for model, results in all_results.items() if 'cv_scores' in results}\n",
        "    if cv_scores:\n",
        "        create_cv_scores_boxplot(cv_scores, list(cv_scores.keys()), axes[1, 0])\n",
        "\n",
        "    # 4. Overall summary\n",
        "    create_model_summary_text(all_results, 'Model Comparison Summary', axes[1, 1])\n",
        "\n",
        "    save_and_show_plot(save_name)\n",
        "\n",
        "print(\"Dashboard functions loaded.\")\n",
        "print(\"You can now collapse this cell and proceed to the preprocessing steps.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F9b_UklmVQo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 2: Data Exploration\n",
        "\n",
        "Comprehensive exploratory data analysis to understand data characteristics.\n",
        "\n",
        "**Key Concepts:**\n",
        "- Missing value patterns and impact assessment\n",
        "- Feature correlations and multicollinearity detection\n",
        "- Distribution shapes and target relationships\n",
        "- Outlier identification and preprocessing needs\n",
        "\n",
        "**Learning Goals:**\n",
        "- Understand your data before preprocessing\n",
        "- Identify preprocessing needs systematically\n",
        "- Make data-driven preprocessing decisions"
      ],
      "metadata": {
        "id": "I1yR8ZqrexgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_data_with_visualizations(df):\n",
        "    \"\"\"\n",
        "    Comprehensive EDA to identify preprocessing needs.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create comprehensive EDA dashboard\n",
        "    create_eda_dashboard(df)\n",
        "\n",
        "    # Extract key insights\n",
        "    missing_counts = df.isnull().sum()\n",
        "    missing_features = missing_counts[missing_counts > 0]\n",
        "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if 'success_score' in numerical_cols:\n",
        "        numerical_cols.remove('success_score')\n",
        "\n",
        "    print(f\"\\nDATASET OVERVIEW:\")\n",
        "    print(f\"   • Shape: {df.shape[0]:,} samples × {df.shape[1]} features\")\n",
        "    print(f\"   • Missing values: {df.isnull().sum().sum():,} total\")\n",
        "\n",
        "    if len(missing_features) > 0:\n",
        "        missing_pct = (missing_features / len(df)) * 100\n",
        "        print(f\"   • Most missing: {missing_features.index[0]} ({missing_pct.iloc[0]:.1f}%)\")\n",
        "\n",
        "    if len(numerical_cols) > 1:\n",
        "        corr_matrix = df[numerical_cols].corr()\n",
        "        corr_matrix_abs = corr_matrix.abs()\n",
        "        np.fill_diagonal(corr_matrix_abs.values, 0)\n",
        "        max_corr = corr_matrix_abs.max().max()\n",
        "        max_corr_pair = corr_matrix_abs.stack().idxmax()\n",
        "        print(f\"   • Strongest correlation: {max_corr_pair[0]} ↔ {max_corr_pair[1]} (r={max_corr:.3f})\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Run exploration\n",
        "explore_data_with_visualizations(dataset)"
      ],
      "metadata": {
        "id": "r3YraONTVuSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 3: Missing Values Handling\n",
        "\n",
        "Handle missing values using different imputation strategies.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Mean imputation**: Replace with average (sensitive to outliers)\n",
        "- **Median imputation**: Replace with middle value (robust)\n",
        "- **Mode imputation**: Replace with most frequent value\n",
        "- **Drop strategy**: Remove rows with missing data\n",
        "---\n",
        "\n",
        "# Exercise\n",
        "\n",
        "- Implement missing strategies: `'mean'`, `'drop'`\n",
        "- Try different strategies and compare their differences"
      ],
      "metadata": {
        "id": "LiDEqdaTe1Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_missing_values(df, strategy='median'):\n",
        "    \"\"\"\n",
        "    Handle missing values using different imputation strategies.\n",
        "    \"\"\"\n",
        "    print(f\"HANDLING MISSING VALUES (Strategy: {strategy.upper()})\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    df_processed = df.copy()\n",
        "    original_missing = df.isnull().sum()\n",
        "    features_with_missing = original_missing[original_missing > 0]\n",
        "\n",
        "    if len(features_with_missing) == 0:\n",
        "        print(\"No missing values found!\")\n",
        "        return df_processed\n",
        "\n",
        "    print(f\"Missing values in {len(features_with_missing)} features\")\n",
        "\n",
        "    # Apply strategy\n",
        "    for feature in features_with_missing.index:\n",
        "        if strategy == 'drop':\n",
        "            printf(\"Implement dropping of rows with missing variables in the row below.\")\n",
        "            df_processed = df_processed\n",
        "            continue\n",
        "\n",
        "        if df[feature].dtype == 'object':\n",
        "            fill_value = df[feature].mode().iloc[0] if len(df[feature].mode()) > 0 else 'Unknown'\n",
        "        else:\n",
        "            if strategy == 'mean':\n",
        "                print(\"Implement mean imputation in the row below.\")\n",
        "                fill_value = 0\n",
        "            elif strategy == 'median':\n",
        "                print(\"Implement median imputation\n",
        "            elif strategy == 'median':\n",
        "                fill_value = df[feature].median()\n",
        "            elif strategy == 'mode':\n",
        "                fill_value = df[feature].mode().iloc[0] if len(df[feature].mode()) > 0 else df[feature].mean()\n",
        "            else:\n",
        "                fill_value = df[feature].median()\n",
        "\n",
        "        df_processed[feature] = df_processed[feature].fillna(fill_value)\n",
        "\n",
        "    final_missing = df_processed.isnull().sum()\n",
        "    print(f\"Missing values: {original_missing.sum()} → {final_missing.sum()}\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 6))\n",
        "\n",
        "    # Before/after comparison\n",
        "    axes[0][0].bar(['Before', 'After'], [original_missing.sum(), final_missing.sum()],\n",
        "               color=['coral', 'lightgreen'])\n",
        "    axes[0][0].set_title('Missing Values: Before vs After')\n",
        "    axes[0][0].set_ylabel('Missing Count')\n",
        "\n",
        "    # Missing pattern\n",
        "    if len(features_with_missing) > 0:\n",
        "        sns.heatmap(df[features_with_missing.index].isnull().head(50).T,\n",
        "                   ax=axes[0][1], cbar=True, yticklabels=True)\n",
        "        axes[0][1].set_title('Missing Pattern (Before)')\n",
        "\n",
        "    # Distribution comparison\n",
        "    numerical_missing = [col for col in features_with_missing.index\n",
        "                        if df[col].dtype in ['int64', 'float64']]\n",
        "    if len(numerical_missing) > 0:\n",
        "        feature = numerical_missing[0]\n",
        "        axes[1][0].hist(df[feature].dropna(), bins=30, alpha=0.7, label='Before', density=True)\n",
        "        axes[1][0].hist(df_processed[feature].dropna(), bins=30, alpha=0.7, label='After', density=True)\n",
        "        axes[1][0].set_title(f'Distribution: {feature}')\n",
        "        axes[1][0].legend()\n",
        "\n",
        "    # Dropped rows\n",
        "    axes[1][1].bar(['Before', 'After'], [df.shape[0], df_processed.shape[0]],\n",
        "                   color=['lightblue', 'lightgreen'])\n",
        "    axes[1][1].set_title(f'Number of samples')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Apply missing value handling - MODIFY strategy to experiment!\n",
        "dataset_step1 = handle_missing_values(dataset, strategy='median')"
      ],
      "metadata": {
        "id": "z4-_8-L0e3MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 4: Categorical Encoding\n",
        "\n",
        "Encode categorical features using appropriate methods.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **One-hot encoding**: For nominal features (no order)\n",
        "- **Ordinal encoding**: For ranked features (already done)\n",
        "\n",
        "**Feature Types:**\n",
        "- Nominal: category, shipping_method, seller_type\n",
        "- Ordinal: product_condition, seller_experience\n",
        "\n",
        "---\n",
        "\n",
        "#Exercise\n",
        "Implement one-hot encoding\n",
        "\n",
        "*Hint: Use the following function: [pandas.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)*"
      ],
      "metadata": {
        "id": "nIbJE5q6e5Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_categorical_features(df):\n",
        "    \"\"\"\n",
        "    Encode categorical features using appropriate methods.\n",
        "    \"\"\"\n",
        "    print(\"ENCODING CATEGORICAL FEATURES\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    df_processed = df.copy()\n",
        "    original_columns = set(df.columns)\n",
        "\n",
        "    # Feature types\n",
        "    nominal_features = ['category', 'shipping_method', 'seller_type']\n",
        "    ordinal_features = ['product_condition', 'seller_experience']\n",
        "\n",
        "    # One-hot encode nominal features\n",
        "    nominal_to_encode = [f for f in nominal_features if f in df.columns]\n",
        "    if nominal_to_encode:\n",
        "        print(f\"One-hot encoding: {', '.join(nominal_to_encode)}\")\n",
        "        print(\"Implement in the row below one-hot encoding\")\n",
        "        df_processed = df_processed\n",
        "\n",
        "    # Ordinal features already encoded\n",
        "    ordinal_present = [f for f in ordinal_features if f in df.columns]\n",
        "    if ordinal_present:\n",
        "        print(f\"Ordinal features (already encoded): {', '.join(ordinal_present)}\")\n",
        "\n",
        "    new_columns = set(df_processed.columns)\n",
        "    added_columns = new_columns - original_columns\n",
        "\n",
        "    print(f\"Features: {len(original_columns)} → {len(new_columns)}\")\n",
        "    print(f\"New features created: {len(added_columns)}\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Feature count comparison\n",
        "    axes[0].bar(['Original', 'After Encoding'], [len(original_columns), len(new_columns)],\n",
        "               color=['coral', 'lightgreen'])\n",
        "    axes[0].set_title('Feature Count Comparison')\n",
        "\n",
        "    # Original categories\n",
        "    if nominal_to_encode:\n",
        "        feature = nominal_to_encode[0]\n",
        "        df[feature].value_counts().plot(kind='bar', ax=axes[1], color='coral', alpha=0.7)\n",
        "        axes[1].set_title(f'Original Categories: {feature}')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # New features sample\n",
        "    if added_columns:\n",
        "        sample_features = list(added_columns)[:5]\n",
        "        text_content = \"New Features:\\n\\n\" + \"\\n\".join(sample_features)\n",
        "        axes[2].text(0.1, 0.9, text_content, transform=axes[2].transAxes, fontsize=10)\n",
        "        axes[2].set_title('Sample New Features')\n",
        "        axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Apply categorical encoding\n",
        "dataset_step2 = encode_categorical_features(dataset_step1)"
      ],
      "metadata": {
        "id": "NkWrSt9Pe7Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 5: Feature Scaling\n",
        "\n",
        "Scale numerical features using different methods.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Standard scaling**: Z-score normalization (mean=0, std=1)\n",
        "- **MinMax scaling**: Scale to 0-1 range\n",
        "- **Robust scaling**: Uses median and IQR (outlier-resistant)\n",
        "\n",
        "---\n",
        "# Exercise\n",
        "- Read [scikit-learn documentation](https://scikit-learn.org/stable/api/sklearn.preprocessing.html) and implement minmax and robust scalers.\n",
        "- Try different scalers and their effect on the range of values"
      ],
      "metadata": {
        "id": "FbzF1zlue9--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_numerical_features(df, scaler_type='standard'):\n",
        "    \"\"\"\n",
        "    Scale numerical features using different methods.\n",
        "    \"\"\"\n",
        "    print(f\"SCALING NUMERICAL FEATURES (Method: {scaler_type.upper()})\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Features to scale (exclude target and binary)\n",
        "    numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    features_to_exclude = ['success_score', 'product_condition', 'seller_experience',\n",
        "                          'has_reviews', 'international_shipping', 'seller_location_code']\n",
        "    features_to_scale = [f for f in numerical_features if f not in features_to_exclude]\n",
        "\n",
        "    if not features_to_scale:\n",
        "        print(\"No numerical features to scale\")\n",
        "        return df_processed, None\n",
        "\n",
        "    print(f\"Features to scale: {', '.join(features_to_scale)}\")\n",
        "\n",
        "    # Select scaler\n",
        "    if scaler_type == 'standard':\n",
        "        scaler = StandardScaler()\n",
        "    elif scaler_type == 'minmax':\n",
        "        print(\"Implement minmax scaler in the row below\")\n",
        "        scaler = None\n",
        "    elif scaler_type == 'robust':\n",
        "        print(\"Implement robust scaler in the row below\")\n",
        "        scaler = None\n",
        "    else:\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "    # Apply scaling\n",
        "    scaled_values = scaler.fit_transform(df_processed[features_to_scale])\n",
        "    df_processed[features_to_scale] = scaled_values\n",
        "\n",
        "    print(f\"Scaled {len(features_to_scale)} features\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    # Before scaling distributions\n",
        "    for i, feature in enumerate(features_to_scale[:4]):\n",
        "        df[feature].dropna().hist(bins=30, alpha=0.6, ax=axes[0,0], label=feature, density=True)\n",
        "    axes[0,0].set_title('Before Scaling')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].set_yscale('log')\n",
        "\n",
        "    # After scaling distributions\n",
        "    for i, feature in enumerate(features_to_scale[:4]):\n",
        "        df_processed[feature].dropna().hist(bins=30, alpha=0.6, ax=axes[0,1], label=feature, density=True)\n",
        "    axes[0,1].set_title(f'After {scaler_type.title()} Scaling')\n",
        "    axes[0,1].legend()\n",
        "\n",
        "    # Before scaling boxplots\n",
        "    df[features_to_scale].boxplot(ax=axes[1,0])\n",
        "    axes[1,0].set_title('Before Scaling (Ranges)')\n",
        "    axes[1,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # After scaling boxplots\n",
        "    df_processed[features_to_scale].boxplot(ax=axes[1,1])\n",
        "    axes[1,1].set_title(f'After {scaler_type.title()} Scaling')\n",
        "    axes[1,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df_processed, scaler\n",
        "\n",
        "# Apply feature scaling - MODIFY scaler_type to experiment!\n",
        "dataset_step3, scaler = scale_numerical_features(dataset_step2, scaler_type='robust')"
      ],
      "metadata": {
        "id": "yCYxsbAje_mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 6: Outlier Detection and Handling\n",
        "\n",
        "Detect and handle outliers using multiple statistical methods.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **IQR Method**: Uses interquartile range (Q3-Q1)\n",
        "- **Z-Score Method**: Uses standard deviations from mean\n",
        "- **Isolation Forest**: ML approach for anomaly detection\n",
        "\n",
        "\n",
        "---\n",
        "#Exercise\n",
        "- Actions: `'remove'`, `'cap'`, `'keep'`\n",
        "- Try different combinations: methods × actions"
      ],
      "metadata": {
        "id": "LjZm_xW2fHxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_handle_outliers(df, method='iqr', action='cap'):\n",
        "    \"\"\"\n",
        "    Detect and handle outliers using different methods and actions.\n",
        "    \"\"\"\n",
        "    print(f\"OUTLIER DETECTION & HANDLING\")\n",
        "    print(f\"Method: {method.upper()} | Action: {action.upper()}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    df_processed = df.copy()\n",
        "    original_shape = df.shape\n",
        "\n",
        "    # Get numerical features (exclude target and binary)\n",
        "    numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    features_to_check = [f for f in numerical_features if f not in\n",
        "                        ['success_score', 'product_condition', 'seller_experience',\n",
        "                         'has_reviews', 'international_shipping', 'seller_location_code']]\n",
        "\n",
        "    if not features_to_check:\n",
        "        print(\"No numerical features found\")\n",
        "        return df_processed\n",
        "\n",
        "    print(f\"Checking {len(features_to_check)} numerical features\")\n",
        "\n",
        "    all_outlier_indices = set()\n",
        "    outlier_summary = {}\n",
        "\n",
        "    # Detect outliers\n",
        "    for feature in features_to_check:\n",
        "        data = df[feature].dropna()\n",
        "        if len(data) == 0:\n",
        "            continue\n",
        "\n",
        "        if method == 'iqr':\n",
        "            Q1, Q3 = data.quantile(0.25), data.quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            outlier_mask = (data < Q1 - 1.5 * IQR) | (data > Q3 + 1.5 * IQR)\n",
        "            outlier_indices = set(data[outlier_mask].index)\n",
        "\n",
        "        elif method == 'zscore':\n",
        "            z_scores = np.abs(stats.zscore(data))\n",
        "            outlier_indices = set(data[z_scores > 3].index)\n",
        "\n",
        "        elif method == 'isolation_forest':\n",
        "            iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
        "            outlier_mask = iso_forest.fit_predict(data.values.reshape(-1, 1)) == -1\n",
        "            outlier_indices = set(data[outlier_mask].index)\n",
        "\n",
        "        outlier_count = len(outlier_indices)\n",
        "        outlier_pct = (outlier_count / len(data)) * 100 if len(data) > 0 else 0\n",
        "        outlier_summary[feature] = {'count': outlier_count, 'percentage': outlier_pct}\n",
        "        all_outlier_indices.update(outlier_indices)\n",
        "\n",
        "        print(f\"   • {feature}: {outlier_count} outliers ({outlier_pct:.1f}%)\")\n",
        "\n",
        "    total_outliers = len(all_outlier_indices)\n",
        "    print(f\"\\nTotal outliers: {total_outliers} ({(total_outliers/len(df)*100):.1f}%)\")\n",
        "\n",
        "    # Apply action\n",
        "    if action == 'remove' and total_outliers > 0:\n",
        "        df_processed = df_processed.drop(index=list(all_outlier_indices))\n",
        "        print(f\"Removed {total_outliers} outlier rows\")\n",
        "\n",
        "    elif action == 'cap' and total_outliers > 0:\n",
        "        print(f\"Capping outliers...\")\n",
        "        for feature in features_to_check:\n",
        "            if outlier_summary[feature]['count'] > 0:\n",
        "                Q1, Q3 = df[feature].quantile(0.25), df[feature].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                df_processed[feature] = df_processed[feature].clip(\n",
        "                    lower=Q1 - 1.5 * IQR, upper=Q3 + 1.5 * IQR)\n",
        "\n",
        "    elif action == 'keep':\n",
        "        print(f\"Keeping all outliers\")\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Outlier counts\n",
        "    if outlier_summary:\n",
        "        features = list(outlier_summary.keys())\n",
        "        counts = [outlier_summary[f]['count'] for f in features]\n",
        "        axes[0].bar(range(len(features)), counts, color='coral')\n",
        "        axes[0].set_xticks(range(len(features)))\n",
        "        axes[0].set_xticklabels([f.replace('_', '\\n') for f in features], rotation=0)\n",
        "        axes[0].set_title(f'Outliers by Feature ({method.upper()})')\n",
        "\n",
        "    # Before/after comparison\n",
        "    if total_outliers > 0 and action != 'keep':\n",
        "        axes[1].bar(['Before', 'After'], [original_shape[0], df_processed.shape[0]],\n",
        "                   color=['lightblue', 'lightgreen'])\n",
        "        axes[1].set_title(f'Dataset Size ({action.title()})')\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'No Action Taken', ha='center', va='center',\n",
        "                    transform=axes[1].transAxes, fontsize=12)\n",
        "        axes[1].set_title('Action Impact')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Dataset shape: {original_shape} → {df_processed.shape}\")\n",
        "    return df_processed\n",
        "\n",
        "# Apply outlier detection - MODIFY parameters to experiment!\n",
        "dataset_step4 = detect_and_handle_outliers(dataset_step3, method='zscore', action='keep')"
      ],
      "metadata": {
        "id": "z1XDkADlfJJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 7: Complete Preprocessing Pipeline\n",
        "\n",
        "Build an end-to-end preprocessing pipeline that applies all steps automatically.\n",
        "\n",
        "**Pipeline Steps:**\n",
        "1. Data validation\n",
        "2. Missing value imputation\n",
        "3. Categorical encoding\n",
        "4. Feature scaling\n",
        "5. Outlier handling\n",
        "6. Final validation\n",
        "\n",
        "---\n",
        "# Exercise\n",
        "Set the configuration for your preferred combination of preprocessing operations and generate the dataset for training."
      ],
      "metadata": {
        "id": "8mXgc-PMfLJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_preprocessing_pipeline(config):\n",
        "    \"\"\"\n",
        "    Create a complete preprocessing pipeline.\n",
        "    \"\"\"\n",
        "    def pipeline(df):\n",
        "        print(\"=\"*60)\n",
        "        print(\"COMPLETE PREPROCESSING PIPELINE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        df_current = df.copy()\n",
        "        original_shape = df.shape\n",
        "        pipeline_log = []\n",
        "\n",
        "        print(f\"Input: {original_shape}\")\n",
        "\n",
        "        # Step 1: Validation\n",
        "        print(f\"\\nSTEP 1: VALIDATION\")\n",
        "        missing_total = df_current.isnull().sum().sum()\n",
        "        print(f\"   Missing values: {missing_total}\")\n",
        "        pipeline_log.append(f\"Validation: {missing_total} missing values\")\n",
        "\n",
        "        # Step 2: Missing Values\n",
        "        if config.get('handle_missing', True):\n",
        "            print(f\"\\nSTEP 2: MISSING VALUES\")\n",
        "            strategy = config.get('missing_strategy', 'median')\n",
        "            df_current = handle_missing_values(df_current, strategy=strategy)\n",
        "            pipeline_log.append(f\"Missing: {strategy} imputation\")\n",
        "\n",
        "        # Step 3: Categorical Encoding\n",
        "        if config.get('encode_categorical', True):\n",
        "            print(f\"\\nSTEP 3: CATEGORICAL ENCODING\")\n",
        "            before_features = df_current.shape[1]\n",
        "            df_current = encode_categorical_features(df_current)\n",
        "            new_features = df_current.shape[1] - before_features\n",
        "            pipeline_log.append(f\"Encoding: +{new_features} features\")\n",
        "\n",
        "        # Step 4: Feature Scaling\n",
        "        if config.get('scale_features', True):\n",
        "            print(f\"\\nSTEP 4: FEATURE SCALING\")\n",
        "            scaler_type = config.get('scaler_type', 'standard')\n",
        "            df_current, fitted_scaler = scale_numerical_features(df_current, scaler_type=scaler_type)\n",
        "            pipeline_log.append(f\"Scaling: {scaler_type}\")\n",
        "        else:\n",
        "            fitted_scaler = None\n",
        "\n",
        "        # Step 5: Outliers\n",
        "        if config.get('handle_outliers', True):\n",
        "            print(f\"\\nSTEP 5: OUTLIERS\")\n",
        "            method = config.get('outlier_method', 'iqr')\n",
        "            action = config.get('outlier_action', 'cap')\n",
        "            df_current = detect_and_handle_outliers(df_current, method=method, action=action)\n",
        "            pipeline_log.append(f\"Outliers: {method} + {action}\")\n",
        "\n",
        "        # Final Summary\n",
        "        final_shape = df_current.shape\n",
        "        print(f\"\\n\" + \"=\"*60)\n",
        "        print(\"PIPELINE SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        for i, log in enumerate(pipeline_log, 1):\n",
        "            print(f\"   {i}. {log}\")\n",
        "\n",
        "        print(f\"\\nCOMPLETED: {original_shape} → {final_shape}\")\n",
        "        print(f\"Dataset ready for modeling!\")\n",
        "\n",
        "        metadata = {\n",
        "            'original_shape': original_shape,\n",
        "            'final_shape': final_shape,\n",
        "            'config': config,\n",
        "            'scaler': fitted_scaler\n",
        "        }\n",
        "\n",
        "        return df_current, metadata\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "# Configure pipeline - MODIFY these parameters!\n",
        "preprocessing_config = {\n",
        "    'handle_missing': True,\n",
        "    'missing_strategy': 'median',      # 'mean', 'median', 'mode', 'drop'\n",
        "    'encode_categorical': True,\n",
        "    'scale_features': False,\n",
        "    'scaler_type': 'standard',         # 'standard', 'minmax', 'robust'\n",
        "    'handle_outliers': True,\n",
        "    'outlier_method': 'iqr',          # 'iqr', 'zscore', 'isolation_forest'\n",
        "    'outlier_action': 'cap'           # 'remove', 'cap', 'keep'\n",
        "}\n",
        "\n",
        "# Create and run pipeline\n",
        "pipeline = create_preprocessing_pipeline(preprocessing_config)\n",
        "final_dataset, metadata = pipeline(dataset)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXPERIMENT: Modify 'preprocessing_config' above!\")\n",
        "print(\"   Try different combinations of parameters\")\n",
        "print(\"   Disable steps by setting to False\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nFINAL DATASET: 'final_dataset' variable created\")\n",
        "\n",
        "X = final_dataset.drop(['success_score', 'listing_id'], axis=1)  # Drop both target AND identifier\n",
        "y = final_dataset['success_score']\n",
        "print(f\"   Shape input X: {X.shape}, shape output y: {y.shape}\")\n"
      ],
      "metadata": {
        "id": "Hru_lGx-fOfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 8: Linear Regression Models\n",
        "\n",
        "Train and compare linear regression models: Linear, Ridge, and Lasso.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Linear Regression**: Simple linear relationship\n",
        "- **Ridge Regression**: L2 regularization prevents overfitting\n",
        "- **Lasso Regression**: L1 regularization enables feature selection\n",
        "\n",
        "Learn more on the [scikit-learn documentation page.](https://scikit-learn.org/stable/modules/linear_model.html)\n",
        "\n",
        "---\n",
        "# Exercise\n",
        "Modify regularization parameters and compare results!"
      ],
      "metadata": {
        "id": "M9Sb1cCkPBqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_linear_regression(X, y, test_size=0.2, cv_folds=5, visualize=True):\n",
        "    \"\"\"\n",
        "    Train and compare linear regression models.\n",
        "    \"\"\"\n",
        "    print(\"TRAINING LINEAR REGRESSION MODELS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_SEED)\n",
        "    print(f\"Data split: {X_train.shape[0]} train, {X_test.shape[0]} test samples\")\n",
        "\n",
        "    # Define models\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Ridge Regression': Ridge(alpha=1.0),\n",
        "        'Lasso Regression': Lasso(alpha=1.0)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Train each model\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        metrics = {\n",
        "            'r2': r2_score(y_test, y_pred),\n",
        "            'mse': mean_squared_error(y_test, y_pred),\n",
        "            'mae': mean_absolute_error(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "        # Cross-validation\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv_folds, scoring='r2')\n",
        "\n",
        "        results[name] = {\n",
        "            'model': model,\n",
        "            'metrics': metrics,\n",
        "            'cv_scores': cv_scores,\n",
        "            'training_time': training_time,\n",
        "            'y_pred': y_pred,\n",
        "            'y_test': y_test\n",
        "        }\n",
        "\n",
        "        print(f\"R² = {metrics['r2']:.3f}, RMSE = {np.sqrt(metrics['mse']):.3f}\")\n",
        "        print(f\"CV Score: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
        "\n",
        "    # Find best model\n",
        "    best_model_name = max(results.keys(), key=lambda x: results[x]['metrics']['r2'])\n",
        "    print(f\"\\nBEST: {best_model_name} (R² = {results[best_model_name]['metrics']['r2']:.3f})\")\n",
        "\n",
        "    # Model insights\n",
        "    lasso_model = results['Lasso Regression']['model']\n",
        "    if hasattr(lasso_model, 'coef_'):\n",
        "        zero_coefs = np.sum(np.abs(lasso_model.coef_) < 1e-10)\n",
        "        print(f\"Lasso zeroed out {zero_coefs} features (feature selection)\")\n",
        "\n",
        "    if visualize:\n",
        "        create_linear_regression_dashboard(results, X_test, y_test)\n",
        "\n",
        "    return results\n",
        "\n",
        "linear_results = train_linear_regression(X, y, visualize=True)"
      ],
      "metadata": {
        "id": "o786XhlmW_-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 9: XGBoost Regression\n",
        "\n",
        "Train XGBoost model with hyperparameter tuning.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Gradient Boosting**: Sequential model building\n",
        "- **Hyperparameters**: n_estimators, max_depth, learning_rate\n",
        "- **Feature Importance**: Tree-based feature ranking\n",
        "\n",
        "---\n",
        "# Exercise\n",
        "- Instantiate the XGBoost regressor.\n",
        " - *Hint: documentation on the [XGBoost webpage](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor)*\n",
        "- Experiment with number of iterations"
      ],
      "metadata": {
        "id": "oWpg9LobYmjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_xgboost_regression(X, y, test_size=0.2, cv_folds=5, n_iter=20, visualize=True):\n",
        "    \"\"\"\n",
        "    Train XGBoost regression model with hyperparameter tuning.\n",
        "    \"\"\"\n",
        "    print(\"TRAINING XGBOOST REGRESSION MODEL\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Handle XGBoost availability\n",
        "    if not XGBOOST_AVAILABLE:\n",
        "        print(\"Using RandomForest instead of XGBoost\")\n",
        "        model_class = None\n",
        "        param_grid = {\n",
        "        }\n",
        "        model_name = \"RandomForest\"\n",
        "    else:\n",
        "        printf(\"Instantiate the XGBoost regressor with a dictionary containing the grid of parameters to explore\")\n",
        "\n",
        "        model_class = None\n",
        "        param_grid = {\n",
        "        }\n",
        "        model_name = \"XGBoost\"\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_SEED)\n",
        "    print(f\"Data split: {X_train.shape[0]} train, {X_test.shape[0]} test samples\")\n",
        "    print(f\"Hyperparameter search iterations: {n_iter}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Hyperparameter search\n",
        "    base_model = model_class(random_state=RANDOM_SEED, n_jobs=-1)\n",
        "    random_search = RandomizedSearchCV(\n",
        "        base_model, param_grid, n_iter=n_iter, cv=cv_folds,\n",
        "        scoring='r2', random_state=RANDOM_SEED, n_jobs=-1\n",
        "    )\n",
        "\n",
        "    print(f\"\\nStarting hyperparameter optimization...\")\n",
        "    random_search.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Get best model\n",
        "    best_model = random_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'r2': r2_score(y_test, y_pred),\n",
        "        'mse': mean_squared_error(y_test, y_pred),\n",
        "        'mae': mean_absolute_error(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_val_score(best_model, X_train, y_train, cv=cv_folds, scoring='r2')\n",
        "\n",
        "    # SHAP values (if available)\n",
        "    shap_values = None\n",
        "    if SHAP_AVAILABLE and XGBOOST_AVAILABLE:\n",
        "        try:\n",
        "            print(f\"Computing SHAP values...\")\n",
        "            sample_size = min(100, X_test.shape[0])\n",
        "            X_sample = X_test.iloc[:sample_size] if hasattr(X_test, 'iloc') else X_test[:sample_size]\n",
        "            explainer = shap.TreeExplainer(best_model)\n",
        "            shap_values = explainer(X_sample)\n",
        "        except:\n",
        "            print(f\"SHAP computation failed\")\n",
        "\n",
        "    # Store results\n",
        "    results = {\n",
        "        'model': best_model,\n",
        "        'metrics': metrics,\n",
        "        'cv_scores': cv_scores,\n",
        "        'training_time': training_time,\n",
        "        'best_params': random_search.best_params_,\n",
        "        'best_cv_score': random_search.best_score_,\n",
        "        'shap_values': shap_values,\n",
        "        'y_pred': y_pred,\n",
        "        'y_test': y_test\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n{model_name} TRAINING COMPLETED!\")\n",
        "    print(f\"R² Score: {metrics['r2']:.3f}\")\n",
        "    print(f\"RMSE: {np.sqrt(metrics['mse']):.3f}\")\n",
        "    print(f\"CV Score: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
        "    print(f\"Training time: {training_time:.2f}s\")\n",
        "\n",
        "    print(f\"\\n BEST HYPERPARAMETERS:\")\n",
        "    for param, value in random_search.best_params_.items():\n",
        "        print(f\"   • {param}: {value}\")\n",
        "\n",
        "    # Feature importance\n",
        "    if hasattr(best_model, 'feature_importances_'):\n",
        "        importances = best_model.feature_importances_\n",
        "        top_features = np.argsort(importances)[-3:][::-1]\n",
        "        print(f\"\\n TOP 3 FEATURES:\")\n",
        "        feature_names = getattr(X, 'columns', [f'Feature_{i}' for i in range(X.shape[1])])\n",
        "        for i, idx in enumerate(top_features):\n",
        "            name = feature_names[idx] if hasattr(feature_names, '__getitem__') else f'Feature_{idx}'\n",
        "            print(f\"   {i+1}. {name}: {importances[idx]:.3f}\")\n",
        "\n",
        "    if visualize:\n",
        "        feature_names = getattr(X, 'columns', [f'Feature_{i}' for i in range(X.shape[1])])\n",
        "        create_xgboost_analysis_dashboard(results, X_test, y_test, feature_names)\n",
        "\n",
        "    return results\n",
        "\n",
        "xgboost_iter = 15\n",
        "xgb_results = train_xgboost_regression(X, y, n_iter=xgboost_iter, visualize=True)"
      ],
      "metadata": {
        "id": "pi7Sbgf-ZAlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 9b: Hyperparameter Search Comparison\n",
        "\n",
        "Compare Grid Search vs Random Search for hyperparameter optimization.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Grid Search**: Exhaustive search through all combinations\n",
        "- **Random Search**: Random sampling from parameter space\n",
        "- **Efficiency**: Time vs performance trade-offs"
      ],
      "metadata": {
        "id": "dFYQaHT-dbX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_hyperparameter_search(X, y, model_type='xgboost', test_size=0.2, cv_folds=5, visualize=True):\n",
        "    \"\"\"\n",
        "    Compare Grid Search vs Random Search for hyperparameter tuning.\n",
        "    \"\"\"\n",
        "    print(f\"COMPARING SEARCH METHODS ({model_type.upper()})\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_SEED)\n",
        "\n",
        "    if model_type == 'xgboost':\n",
        "        if XGBOOST_AVAILABLE:\n",
        "            model = xgb.XGBRegressor(random_state=RANDOM_SEED, n_jobs=-1)\n",
        "            param_grid = {\n",
        "                'n_estimators': [100, 200],\n",
        "                'max_depth': [3, 4, 5],\n",
        "                'learning_rate': [0.01, 0.1, 0.2]\n",
        "            }\n",
        "        else:\n",
        "            model = RandomForestRegressor(random_state=RANDOM_SEED, n_jobs=-1)\n",
        "            param_grid = {\n",
        "                'n_estimators': [100, 200],\n",
        "                'max_depth': [3, 5, 7],\n",
        "                'min_samples_split': [2, 5, 10]\n",
        "            }\n",
        "        X_train_processed, X_test_processed = X_train, X_test\n",
        "\n",
        "    elif model_type == 'neural_network':\n",
        "        model = MLPRegressor(random_state=RANDOM_SEED, max_iter=500)\n",
        "        param_grid = {\n",
        "            'hidden_layer_sizes': [(50,), (100,), (50, 25)],\n",
        "            'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "            'alpha': [0.0001, 0.001, 0.01]\n",
        "        }\n",
        "        # Scale data for neural network\n",
        "        scaler = StandardScaler()\n",
        "        X_train_processed = scaler.fit_transform(X_train)\n",
        "        X_test_processed = scaler.transform(X_test)\n",
        "\n",
        "    total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
        "    print(f\"Total parameter combinations: {total_combinations}\")\n",
        "\n",
        "    # Grid Search\n",
        "    print(f\"\\nRunning Grid Search...\")\n",
        "    grid_start_time = time.time()\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=cv_folds, scoring='r2', n_jobs=-1)\n",
        "    grid_search.fit(X_train_processed, y_train)\n",
        "    grid_time = time.time() - grid_start_time\n",
        "\n",
        "    # Random Search\n",
        "    print(f\"Running Random Search...\")\n",
        "    random_start_time = time.time()\n",
        "    random_search = RandomizedSearchCV(model, param_grid, n_iter=15, cv=cv_folds,\n",
        "                                     scoring='r2', random_state=RANDOM_SEED, n_jobs=-1)\n",
        "    random_search.fit(X_train_processed, y_train)\n",
        "    random_time = time.time() - random_start_time\n",
        "\n",
        "    # Compare results\n",
        "    grid_score = grid_search.best_score_\n",
        "    random_score = random_search.best_score_\n",
        "    score_diff = abs(grid_score - random_score)\n",
        "    time_ratio = grid_time / random_time\n",
        "\n",
        "    print(f\"\\nRESULTS COMPARISON:\")\n",
        "    print(f\"Grid Search: R² = {grid_score:.4f}, Time = {grid_time:.1f}s\")\n",
        "    print(f\"Random Search: R² = {random_score:.4f}, Time = {random_time:.1f}s\")\n",
        "\n",
        "    winner = \"Random Search\" if random_score >= grid_score else \"Grid Search\"\n",
        "    print(f\"\\nWinner: {winner}\")\n",
        "    print(f\"Random Search is {time_ratio:.1f}x faster\")\n",
        "    print(f\"Score difference: {score_diff:.4f}\")\n",
        "\n",
        "    # Create simple visualization\n",
        "    if visualize:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        fig.suptitle('Hyperparameter Search Comparison', fontweight='bold')\n",
        "\n",
        "        # Performance comparison\n",
        "        methods = ['Grid Search', 'Random Search']\n",
        "        scores = [grid_score, random_score]\n",
        "        ax1.bar(methods, scores, color=['coral', 'lightgreen'])\n",
        "        ax1.set_title('Performance Comparison')\n",
        "        ax1.set_ylabel('R² Score')\n",
        "\n",
        "        # Time comparison\n",
        "        times = [grid_time, random_time]\n",
        "        ax2.bar(methods, times, color=['coral', 'lightgreen'])\n",
        "        ax2.set_title('Time Comparison')\n",
        "        ax2.set_ylabel('Time (seconds)')\n",
        "\n",
        "        save_and_show_plot('hyperparameter_comparison.png')\n",
        "\n",
        "    return {\n",
        "        'grid_score': grid_score,\n",
        "        'random_score': random_score,\n",
        "        'winner': winner,\n",
        "        'time_ratio': time_ratio\n",
        "    }\n",
        "\n",
        "hp_comparison = compare_hyperparameter_search(X, y, model_type='xgboost', visualize=True)"
      ],
      "metadata": {
        "id": "W7iaILPpdjfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 10: Neural Network Regression\n",
        "\n",
        "Train Neural Network with architecture search.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Multi-layer Perceptron**: Feedforward network with hidden layers\n",
        "- **Architecture Search**: Finding optimal network structure\n",
        "- **Feature Scaling**: Critical for neural networks\n",
        "- **Regularization**: Early stopping, L2 penalty (alpha)\n",
        "\n",
        "\n",
        "---\n",
        "# Exercise\n",
        "- Instantiate the neural network\n",
        " - *Hint : constructor documentation in the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html)*.\n",
        "- Try different architecture complexities."
      ],
      "metadata": {
        "id": "10y8PHaBa-NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_neural_network_regression(X, y, test_size=0.2, cv_folds=5, n_iter=15, visualize=True):\n",
        "    \"\"\"\n",
        "    Train Neural Network regression model with architecture search.\n",
        "    \"\"\"\n",
        "    print(\"TRAINING NEURAL NETWORK REGRESSION MODEL\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_SEED)\n",
        "    print(f\"Data split: {X_train.shape[0]} train, {X_test.shape[0]} test samples\")\n",
        "\n",
        "    # Scale features (critical for neural networks!)\n",
        "    print(f\"Scaling features for neural network...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    print(f\"   Features scaled (mean=0, std=1)\")\n",
        "\n",
        "    # Define architecture search space\n",
        "    param_grid = {\n",
        "        'hidden_layer_sizes': [\n",
        "            (50,), (100,), (150,),  # Single layer\n",
        "            (50, 25), (100, 50), (150, 75),  # Two layers\n",
        "            (100, 50, 25)  # Three layers\n",
        "        ],\n",
        "        'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "        'alpha': [0.0001, 0.001, 0.01],  # L2 regularization\n",
        "        'max_iter': [500, 1000]\n",
        "    }\n",
        "\n",
        "    print(f\"Architecture search: {len(param_grid['hidden_layer_sizes'])} architectures\")\n",
        "    print(f\"Search iterations: {n_iter}\")\n",
        "\n",
        "    # Show example architectures\n",
        "    print(f\"\\nEXAMPLE ARCHITECTURES:\")\n",
        "    for i, arch in enumerate(param_grid['hidden_layer_sizes'][:3]):\n",
        "        layers_str = f\"{X.shape[1]} → \" + \" → \".join(map(str, arch)) + \" → 1\"\n",
        "        print(f\"   {i+1}. {layers_str}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create neural network with early stopping\n",
        "    print(\"Instantiate MLP Regressor\")\n",
        "    nn_model = None\n",
        "\n",
        "    # Architecture search\n",
        "    print(f\"\\nStarting neural architecture search...\")\n",
        "    random_search = RandomizedSearchCV(\n",
        "        nn_model, param_grid, n_iter=n_iter, cv=cv_folds,\n",
        "        scoring='r2', random_state=RANDOM_SEED, n_jobs=-1\n",
        "    )\n",
        "    random_search.fit(X_train_scaled, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Get best model\n",
        "    best_model = random_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'r2': r2_score(y_test, y_pred),\n",
        "        'mse': mean_squared_error(y_test, y_pred),\n",
        "        'mae': mean_absolute_error(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=cv_folds, scoring='r2')\n",
        "    training_history = getattr(best_model, 'loss_curve_', None)\n",
        "\n",
        "    # Store results\n",
        "    results = {\n",
        "        'model': best_model,\n",
        "        'scaler': scaler,\n",
        "        'metrics': metrics,\n",
        "        'cv_scores': cv_scores,\n",
        "        'training_time': training_time,\n",
        "        'best_params': random_search.best_params_,\n",
        "        'best_cv_score': random_search.best_score_,\n",
        "        'training_history': training_history,\n",
        "        'y_pred': y_pred,\n",
        "        'y_test': y_test\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nNEURAL NETWORK TRAINING COMPLETED!\")\n",
        "    print(f\"   R² Score: {metrics['r2']:.3f}\")\n",
        "    print(f\"   RMSE: {np.sqrt(metrics['mse']):.3f}\")\n",
        "    print(f\"   CV Score: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
        "    print(f\"   Training time: {training_time:.2f}s\")\n",
        "\n",
        "    # Architecture details\n",
        "    print(f\"\\nOPTIMAL ARCHITECTURE:\")\n",
        "    best_arch = random_search.best_params_['hidden_layer_sizes']\n",
        "    layers_str = f\"{X.shape[1]} → \" + \" → \".join(map(str, best_arch)) + \" → 1\"\n",
        "    print(f\"   {layers_str}\")\n",
        "\n",
        "    print(f\"\\nBEST HYPERPARAMETERS:\")\n",
        "    for param, value in random_search.best_params_.items():\n",
        "        print(f\"   • {param}: {value}\")\n",
        "\n",
        "    # Training insights\n",
        "    if training_history is not None:\n",
        "        print(f\"\\nTRAINING INSIGHTS:\")\n",
        "        print(f\"   • Training iterations: {len(training_history)}\")\n",
        "        print(f\"   • Final loss: {training_history[-1]:.4f}\")\n",
        "        print(f\"   • Early stopping: {'Yes' if len(training_history) < random_search.best_params_['max_iter'] else 'No'}\")\n",
        "\n",
        "    if visualize:\n",
        "        create_neural_network_dashboard(results, X_test_scaled, y_test)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "nn_iter = 10\n",
        "nn_results = train_neural_network_regression(X, y, n_iter=nn_iter, visualize=True)"
      ],
      "metadata": {
        "id": "N0SLmcWna8T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 11: Complete Model Comparison\n",
        "\n",
        "Comprehensive head-to-head comparison of all trained models.\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Model Performance**: R², RMSE, MAE across all models\n",
        "- **Cross-validation**: Robust performance estimation\n",
        "- **Model Selection**: Choosing the best model for deployment\n"
      ],
      "metadata": {
        "id": "GlJNIwayd-pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training_pipeline_demo(X, y, create_visualizations=True):\n",
        "    \"\"\"\n",
        "    Demonstrates the complete model training pipeline step by step.\n",
        "    Students can run this to see the full model selection process.\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix\n",
        "        y: Target variable\n",
        "        create_visualizations: Whether to create dashboard visualizations\n",
        "\n",
        "    Returns:\n",
        "        dict: Complete results from all training steps\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"COMPLETE MODEL TRAINING PIPELINE DEMONSTRATION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    pipeline_results = {}\n",
        "\n",
        "    # Step 1: Data Validation\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 1: DATA VALIDATION & PREPARATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"Dataset Overview:\")\n",
        "    print(f\"   • Samples: {X.shape[0]:,}\")\n",
        "    print(f\"   • Features: {X.shape[1]:,}\")\n",
        "    print(f\"   • Target range: {y.min():.3f} to {y.max():.3f}\")\n",
        "    print(f\"   • Target mean: {y.mean():.3f} (±{y.std():.3f})\")\n",
        "\n",
        "    # Check for missing values\n",
        "    missing_features = X.isnull().sum().sum() if hasattr(X, 'isnull') else 0\n",
        "    missing_target = y.isnull().sum() if hasattr(y, 'isnull') else 0\n",
        "\n",
        "    print(f\"\\nData Quality Check:\")\n",
        "    print(f\"   • Missing values in features: {missing_features}\")\n",
        "    print(f\"   • Missing values in target: {missing_target}\")\n",
        "\n",
        "    if missing_features == 0 and missing_target == 0:\n",
        "        print(f\"   Data quality: EXCELLENT - No missing values\")\n",
        "    else:\n",
        "        print(f\"   Data quality: CAUTION - Missing values detected\")\n",
        "\n",
        "    pipeline_results['data_validation'] = {\n",
        "        'n_samples': X.shape[0],\n",
        "        'n_features': X.shape[1],\n",
        "        'target_stats': {'mean': y.mean(), 'std': y.std(), 'min': y.min(), 'max': y.max()},\n",
        "        'missing_features': missing_features,\n",
        "        'missing_target': missing_target\n",
        "    }\n",
        "\n",
        "    # Step 2: Linear Regression Baseline\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 2: LINEAR REGRESSION BASELINE\")\n",
        "    print(\"=\"*60)\n",
        "    linear_results = train_linear_regression(X, y, visualize=create_visualizations)\n",
        "    pipeline_results['linear_models'] = linear_results\n",
        "\n",
        "    # Step 3: Tree-based Model Training\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 3: TREE-BASED MODEL TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "    xgb_results = train_xgboost_regression(X, y, n_iter=xgboost_iter, visualize=create_visualizations)\n",
        "    pipeline_results['tree_model'] = xgb_results\n",
        "\n",
        "    # Step 4: Neural Network Training\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 4: NEURAL NETWORK TRAINING\")\n",
        "    print(\"=\"*60)\n",
        "    nn_results = train_neural_network_regression(X, y, n_iter=nn_iter, visualize=create_visualizations)\n",
        "    pipeline_results['neural_network'] = nn_results\n",
        "\n",
        "    # Step 5: Cross-validation Analysis\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 5: CROSS-VALIDATION ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    cv_results = cross_validate_models(X, y, visualize=create_visualizations)\n",
        "    pipeline_results['cross_validation'] = cv_results\n",
        "\n",
        "    # Step 6: Final Model Selection\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 6: FINAL MODEL SELECTION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Compile all models for comparison\n",
        "    all_models = {}\n",
        "\n",
        "    # Best linear model\n",
        "    best_linear_name = max(linear_results.keys(), key=lambda x: linear_results[x]['metrics']['r2'])\n",
        "    all_models[f'Linear ({best_linear_name})'] = linear_results[best_linear_name]\n",
        "\n",
        "    # Tree-based model\n",
        "    model_name = 'XGBoost' if XGBOOST_AVAILABLE else 'RandomForest'\n",
        "    all_models[model_name] = xgb_results\n",
        "\n",
        "    # Neural network\n",
        "    all_models['Neural Network'] = nn_results\n",
        "\n",
        "    # Final selection based on multiple criteria\n",
        "    print(f\"FINAL MODEL SELECTION ANALYSIS:\")\n",
        "    print(f\"\\nPerformance Summary:\")\n",
        "\n",
        "    selection_criteria = {}\n",
        "    for model_name, results in all_models.items():\n",
        "        r2_score = results['metrics']['r2']\n",
        "        cv_mean = np.mean(results['cv_scores'])\n",
        "        cv_std = np.std(results['cv_scores'])\n",
        "        training_time = results.get('training_time', 0)\n",
        "\n",
        "        # Composite score: performance + consistency + efficiency\n",
        "        performance_score = (r2_score + cv_mean) / 2  # Average test and CV performance\n",
        "        consistency_score = 1 - cv_std  # Reward low variance\n",
        "        efficiency_score = 1 / (training_time + 1)  # Reward fast training\n",
        "\n",
        "        composite_score = (performance_score * 0.7 + consistency_score * 0.2 + efficiency_score * 0.1)\n",
        "\n",
        "        selection_criteria[model_name] = {\n",
        "            'r2_score': r2_score,\n",
        "            'cv_mean': cv_mean,\n",
        "            'cv_std': cv_std,\n",
        "            'training_time': training_time,\n",
        "            'composite_score': composite_score\n",
        "        }\n",
        "\n",
        "        print(f\"   {model_name}:\")\n",
        "        print(f\"      • Test R²: {r2_score:.3f}\")\n",
        "        print(f\"      • CV Mean: {cv_mean:.3f} (±{cv_std:.3f})\")\n",
        "        print(f\"      • Training Time: {training_time:.2f}s\")\n",
        "        print(f\"      • Composite Score: {composite_score:.3f}\")\n",
        "\n",
        "    # Select final model\n",
        "    final_model_name = max(selection_criteria.keys(), key=lambda x: selection_criteria[x]['composite_score'])\n",
        "    final_model_results = all_models[final_model_name]\n",
        "\n",
        "    print(f\"\\nSELECTED MODEL: {final_model_name}\")\n",
        "    print(f\"   Final R² Score: {final_model_results['metrics']['r2']:.3f}\")\n",
        "    print(f\"   CV Performance: {np.mean(final_model_results['cv_scores']):.3f} (±{np.std(final_model_results['cv_scores']):.3f})\")\n",
        "    print(f\"   Training Time: {final_model_results.get('training_time', 0):.2f}s\")\n",
        "\n",
        "    # Model-specific insights\n",
        "    print(f\"\\nMODEL INSIGHTS:\")\n",
        "    if final_model_name.startswith('Linear'):\n",
        "        print(f\"   • Linear relationship dominates the data\")\n",
        "        print(f\"   • Model is highly interpretable and fast\")\n",
        "        print(f\"   • Good choice for production deployment\")\n",
        "    elif 'XGBoost' in final_model_name or 'RandomForest' in final_model_name:\n",
        "        print(f\"   • Complex non-linear patterns in the data\")\n",
        "        print(f\"   • Feature importance available for interpretability\")\n",
        "        print(f\"   • Robust to different data types and missing values\")\n",
        "    else:\n",
        "        print(f\"   • Very complex patterns requiring neural networks\")\n",
        "        print(f\"   • High model capacity for complex relationships\")\n",
        "        print(f\"   • May require more data and careful tuning\")\n",
        "\n",
        "    pipeline_results['final_selection'] = {\n",
        "        'selected_model': final_model_name,\n",
        "        'model_results': final_model_results,\n",
        "        'selection_criteria': selection_criteria\n",
        "    }\n",
        "\n",
        "    # Step 7: Production Readiness Assessment\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 7: PRODUCTION READINESS ASSESSMENT\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    final_r2 = final_model_results['metrics']['r2']\n",
        "    cv_std = np.std(final_model_results['cv_scores'])\n",
        "\n",
        "    print(f\"PRODUCTION READINESS CHECKLIST:\")\n",
        "\n",
        "    # Performance check\n",
        "    if final_r2 > 0.8:\n",
        "        print(f\"   Performance: EXCELLENT (R² > 0.8)\")\n",
        "        performance_status = \"EXCELLENT\"\n",
        "    elif final_r2 > 0.6:\n",
        "        print(f\"   Performance: GOOD (R² > 0.6)\")\n",
        "        performance_status = \"GOOD\"\n",
        "    elif final_r2 > 0.4:\n",
        "        print(f\"   Performance: ACCEPTABLE (R² > 0.4)\")\n",
        "        performance_status = \"ACCEPTABLE\"\n",
        "    else:\n",
        "        print(f\"   Performance: POOR (R² < 0.4)\")\n",
        "        performance_status = \"POOR\"\n",
        "\n",
        "    # Stability check\n",
        "    if cv_std < 0.05:\n",
        "        print(f\"   Stability: EXCELLENT (CV std < 0.05)\")\n",
        "        stability_status = \"EXCELLENT\"\n",
        "    elif cv_std < 0.1:\n",
        "        print(f\"   Stability: GOOD (CV std < 0.1)\")\n",
        "        stability_status = \"GOOD\"\n",
        "    else:\n",
        "        print(f\"   Stability: CONCERNING (High CV variance)\")\n",
        "        stability_status = \"CONCERNING\"\n",
        "\n",
        "    # Overall recommendation\n",
        "    if performance_status in [\"EXCELLENT\", \"GOOD\"] and stability_status in [\"EXCELLENT\", \"GOOD\"]:\n",
        "        deployment_recommendation = \"READY FOR PRODUCTION\"\n",
        "        print(f\"\\nDEPLOYMENT RECOMMENDATION: {deployment_recommendation}\")\n",
        "        print(f\"   • Model performance and stability are suitable for production\")\n",
        "        print(f\"   • Proceed with deployment planning and monitoring setup\")\n",
        "    elif performance_status == \"ACCEPTABLE\":\n",
        "        deployment_recommendation = \"DEPLOY WITH MONITORING\"\n",
        "        print(f\"\\nDEPLOYMENT RECOMMENDATION: {deployment_recommendation}\")\n",
        "        print(f\"   • Model performance is acceptable but requires close monitoring\")\n",
        "        print(f\"   • Consider collecting more data or feature engineering\")\n",
        "    else:\n",
        "        deployment_recommendation = \"NOT READY - REQUIRES IMPROVEMENT\"\n",
        "        print(f\"\\nDEPLOYMENT RECOMMENDATION: {deployment_recommendation}\")\n",
        "        print(f\"   • Model performance is insufficient for production use\")\n",
        "        print(f\"   • Collect more data, improve features, or try different approaches\")\n",
        "\n",
        "    pipeline_results['production_assessment'] = {\n",
        "        'performance_status': performance_status,\n",
        "        'stability_status': stability_status,\n",
        "        'deployment_recommendation': deployment_recommendation\n",
        "    }\n",
        "\n",
        "    # Final Summary\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MODEL TRAINING PIPELINE COMPLETED!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    create_pipeline_summary(pipeline_results)\n",
        "\n",
        "    return pipeline_results\n",
        "\n",
        "\n",
        "def cross_validate_models(X, y, cv_folds=5, visualize=True):\n",
        "    \"\"\"\n",
        "    Perform detailed cross-validation analysis on all model families.\n",
        "    \"\"\"\n",
        "    print(\"CROSS-VALIDATION ANALYSIS\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Define models for cross-validation\n",
        "    models = {\n",
        "        'Linear Regression': LinearRegression(),\n",
        "        'Ridge Regression': Ridge(alpha=1.0)\n",
        "    }\n",
        "\n",
        "    # Add tree-based model\n",
        "    if XGBOOST_AVAILABLE:\n",
        "        models['XGBoost'] = xgb.XGBRegressor(random_state=RANDOM_SEED, n_jobs=-1, n_estimators=100)\n",
        "    else:\n",
        "        models['RandomForest'] = RandomForestRegressor(random_state=RANDOM_SEED, n_jobs=-1, n_estimators=100)\n",
        "\n",
        "    # Add neural network (with scaling)\n",
        "    models['Neural Network'] = MLPRegressor(\n",
        "        hidden_layer_sizes=(100, 50), random_state=RANDOM_SEED, max_iter=500\n",
        "    )\n",
        "\n",
        "    cv_results = {}\n",
        "    scaler = StandardScaler()  # For neural network\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Perform cross-validation for each model\n",
        "    for name, model in models.items():\n",
        "        print(f\"Cross-validating {name}...\")\n",
        "\n",
        "        # Use scaled data for neural network, original for others\n",
        "        X_to_use = X_scaled if 'Neural' in name else X\n",
        "\n",
        "        # Perform cross-validation\n",
        "        scores = cross_val_score(model, X_to_use, y, cv=cv_folds, scoring='r2')\n",
        "\n",
        "        cv_results[name] = {\n",
        "            'scores': scores,\n",
        "            'mean': np.mean(scores),\n",
        "            'std': np.std(scores),\n",
        "            'min': np.min(scores),\n",
        "            'max': np.max(scores)\n",
        "        }\n",
        "\n",
        "        print(f\"  {name}: {np.mean(scores):.3f} (±{np.std(scores):.3f})\")\n",
        "\n",
        "    # Print detailed results\n",
        "    print(f\"\\nCROSS-VALIDATION SUMMARY:\")\n",
        "    print(\"-\" * 50)\n",
        "    for name, results in cv_results.items():\n",
        "        print(f\"{name}:\")\n",
        "        print(f\"  • Mean R²: {results['mean']:.3f}\")\n",
        "        print(f\"  • Std Dev: {results['std']:.3f}\")\n",
        "        print(f\"  • Range: {results['min']:.3f} - {results['max']:.3f}\")\n",
        "        print()\n",
        "\n",
        "    if visualize:\n",
        "        # Create cross-validation visualization\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        fig.suptitle('Cross-Validation Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # 1. CV scores boxplot\n",
        "        create_cv_scores_boxplot(\n",
        "            {model: cv_results[model]['scores'] for model in cv_results.keys()},\n",
        "            list(cv_results.keys()), axes[0]\n",
        "        )\n",
        "\n",
        "        # 2. Mean scores comparison\n",
        "        mean_scores = {model: cv_results[model]['mean'] for model in cv_results.keys()}\n",
        "        create_performance_comparison_chart(\n",
        "            {model: {'metrics': {'r2': mean_scores[model]}} for model in mean_scores.keys()},\n",
        "            'r2', 'Cross-Validation Mean R² Scores', axes[1]\n",
        "        )\n",
        "\n",
        "        save_and_show_plot('cross_validation_analysis.png')\n",
        "\n",
        "    print(f\"Cross-validation analysis completed!\")\n",
        "    return cv_results\n",
        "\n",
        "\n",
        "def create_pipeline_summary(pipeline_results):\n",
        "    \"\"\"\n",
        "    Create a comprehensive summary of the model training pipeline.\n",
        "    \"\"\"\n",
        "    print(f\"\\nMODEL TRAINING PIPELINE SUMMARY\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Data summary\n",
        "    data_info = pipeline_results['data_validation']\n",
        "    print(f\"DATASET SUMMARY:\")\n",
        "    print(f\"   • Samples: {data_info['n_samples']:,}\")\n",
        "    print(f\"   • Features: {data_info['n_features']:,}\")\n",
        "    print(f\"   • Target Range: {data_info['target_stats']['min']:.3f} to {data_info['target_stats']['max']:.3f}\")\n",
        "    print(f\"   • Data Quality: {'EXCELLENT' if data_info['missing_features'] == 0 else 'NEEDS ATTENTION'}\")\n",
        "\n",
        "    # Model performance summary\n",
        "    final_selection = pipeline_results['final_selection']\n",
        "    selected_model = final_selection['selected_model']\n",
        "    model_results = final_selection['model_results']\n",
        "\n",
        "    print(f\"\\nSELECTED MODEL: {selected_model}\")\n",
        "    print(f\"   • R² Score: {model_results['metrics']['r2']:.3f}\")\n",
        "    print(f\"   • RMSE: {np.sqrt(model_results['metrics']['mse']):.3f}\")\n",
        "    print(f\"   • MAE: {model_results['metrics']['mae']:.3f}\")\n",
        "    print(f\"   • CV Performance: {np.mean(model_results['cv_scores']):.3f} (±{np.std(model_results['cv_scores']):.3f})\")\n",
        "\n",
        "    # Production readiness\n",
        "    prod_assessment = pipeline_results['production_assessment']\n",
        "    print(f\"\\nPRODUCTION READINESS: {prod_assessment['deployment_recommendation']}\")\n",
        "    print(f\"   • Performance Status: {prod_assessment['performance_status']}\")\n",
        "    print(f\"   • Stability Status: {prod_assessment['stability_status']}\")\n",
        "\n",
        "    # Key learnings\n",
        "    print(f\"\\n🎓 KEY LEARNINGS:\")\n",
        "    print(f\"   • Model Selection: Systematic comparison of multiple approaches\")\n",
        "    print(f\"   • Cross-validation: Essential for robust performance estimation\")\n",
        "    print(f\"   • Hyperparameter Tuning: Can significantly improve performance\")\n",
        "    print(f\"   • Production Considerations: Performance + Stability + Interpretability\")\n",
        "\n",
        "    print(f\"\\nPipeline completed successfully!\")\n",
        "    print(f\"   The model is ready for the next phase of development!\")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "pipeline_results = model_training_pipeline_demo(X, y, create_visualizations=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODULE 3 COMPLETE!\")\n",
        "print(\"You have learned:\")\n",
        "print(\"   • Linear Regression Models (Linear, Ridge, Lasso)\")\n",
        "print(\"   • Tree-based Models (XGBoost/RandomForest)\")\n",
        "print(\"   • Neural Networks (Multi-layer Perceptron)\")\n",
        "print(\"   • Hyperparameter Optimization (Grid vs Random Search)\")\n",
        "print(\"   • Model Comparison and Selection\")\n",
        "print(\"   • Cross-validation and Production Readiness\")\n",
        "print(\"\\nCongratulations! You now have production-level ML skills!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "xCkOaM9wecjT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}